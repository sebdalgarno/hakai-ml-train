{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - Metrics\n",
    "\n",
    "Run model evaluations and save results to CSV files in `outputs/eval-metrics/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.data import NpzSegmentationDataset\n",
    "from src.models.smp import SMPMulticlassSegmentationModel\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR = Path(\"../outputs/eval-metrics\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(config_path, ckpt_path, split=\"val\"):\n",
    "    \"\"\"Evaluate a model and return IoU, Precision, Recall for seagrass class.\"\"\"\n",
    "    \n",
    "    # Load config\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    model_args = config[\"model\"][\"init_args\"]\n",
    "    data_args = config[\"data\"][\"init_args\"]\n",
    "    \n",
    "    # Select data split\n",
    "    if split == \"val\":\n",
    "        chip_dir = data_args[\"val_chip_dir\"]\n",
    "    else:\n",
    "        chip_dir = data_args[\"test_chip_dir\"]\n",
    "    \n",
    "    # Load dataset\n",
    "    test_transforms = A.from_dict(data_args[\"test_transforms\"])\n",
    "    dataset = NpzSegmentationDataset(chip_dir, transforms=test_transforms)\n",
    "    loader = DataLoader(dataset, batch_size=8, num_workers=4, shuffle=False)\n",
    "    \n",
    "    # Load model\n",
    "    model = SMPMulticlassSegmentationModel.load_from_checkpoint(ckpt_path, map_location=DEVICE)\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # Create metrics\n",
    "    num_classes = model_args[\"num_classes\"]\n",
    "    ignore_index = model_args.get(\"ignore_index\", -100)\n",
    "    \n",
    "    iou = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=num_classes, \n",
    "                                     ignore_index=ignore_index, average=\"none\").to(DEVICE)\n",
    "    precision = torchmetrics.Precision(task=\"multiclass\", num_classes=num_classes,\n",
    "                                        ignore_index=ignore_index, average=\"none\").to(DEVICE)\n",
    "    recall = torchmetrics.Recall(task=\"multiclass\", num_classes=num_classes,\n",
    "                                  ignore_index=ignore_index, average=\"none\").to(DEVICE)\n",
    "    \n",
    "    # Evaluate\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            probs = torch.softmax(model(images), dim=1)\n",
    "            iou.update(probs, labels)\n",
    "            precision.update(probs, labels)\n",
    "            recall.update(probs, labels)\n",
    "    \n",
    "    # Return seagrass class metrics (index 1)\n",
    "    results = {\n",
    "        \"IoU\": iou.compute()[1].item(),\n",
    "        \"Precision\": precision.compute()[1].item(),\n",
    "        \"Recall\": recall.compute()[1].item(),\n",
    "    }\n",
    "    \n",
    "    # Cleanup\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Architecture Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture experiment models\n",
    "ARCH_MODELS = {\n",
    "    \"UNet_512\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/architecture-experiment/unetpp_resnet34_512.yaml\",\n",
    "        \"ckpt\": \"../seagrass-rgb/qjfpb4m8/checkpoints/unetpp_resnet34_512_epoch-199_val-iou-0.7050.ckpt\",\n",
    "    },\n",
    "    \"UNet_1024\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/architecture-experiment/unetpp_resnet34_1024.yaml\",\n",
    "        \"ckpt\": \"../seagrass-rgb/mdqn7se0/checkpoints/unetpp_resnet34_1024_epoch-199_val-iou-0.7247.ckpt\",\n",
    "    },\n",
    "    \"Seg_512\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/architecture-experiment/segformer_mitb2_512.yaml\",\n",
    "        \"ckpt\": \"../seagrass-rgb/3uav2blr/checkpoints/segformer_mitb2_512_epoch-199_val-iou-0.7425.ckpt\",\n",
    "    },\n",
    "    \"Seg_1024\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/architecture-experiment/segformer_mitb2_1024.yaml\",\n",
    "        \"ckpt\": \"../seagrass-rgb/jhf1t0ih/checkpoints/segformer_mitb2_1024_epoch-199_val-iou-0.7909.ckpt\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Evaluate all architecture models\n",
    "arch_results = {}\n",
    "for name, paths in ARCH_MODELS.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    arch_results[name] = evaluate_model(paths[\"config\"], paths[\"ckpt\"], split=\"val\")\n",
    "    print(f\"  IoU: {arch_results[name]['IoU']:.4f}\")\n",
    "\n",
    "arch_df = pd.DataFrame(arch_results).T\n",
    "arch_df.to_csv(OUTPUT_DIR / \"architecture_experiment.csv\")\n",
    "arch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Augmentation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation experiment models (Note: Baseline checkpoint not available)\n",
    "AUG_MODELS = {\n",
    "    \"Baseline\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/augmentation-experiment/segformer_baseline_aug.yaml\",\n",
    "        \"ckpt\": \"/mnt/class_data/sdalgarno/checkpoints/augmentation-experiment/baseline/last.ckpt\",\n",
    "    },\n",
    "    \"Default\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/augmentation-experiment/segformer_default_aug.yaml\",\n",
    "        \"ckpt\": \"/mnt/class_data/sdalgarno/checkpoints/augmentation-experiment/default/last.ckpt\",\n",
    "    },\n",
    "    \"Scale\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/augmentation-experiment/segformer_scale_aug.yaml\",\n",
    "        \"ckpt\": \"/mnt/class_data/sdalgarno/checkpoints/augmentation-experiment/scale/last.ckpt\",\n",
    "    },\n",
    "    \"Domain\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/augmentation-experiment/segformer_domain_aug.yaml\",\n",
    "        \"ckpt\": \"/mnt/class_data/sdalgarno/checkpoints/augmentation-experiment/domain/last.ckpt\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Evaluate all augmentation models\n",
    "aug_results = {}\n",
    "for name, paths in AUG_MODELS.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    aug_results[name] = evaluate_model(paths[\"config\"], paths[\"ckpt\"], split=\"val\")\n",
    "    print(f\"  IoU: {aug_results[name]['IoU']:.4f}\")\n",
    "\n",
    "aug_df = pd.DataFrame(aug_results).T\n",
    "aug_df.to_csv(OUTPUT_DIR / \"augmentation_experiment.csv\")\n",
    "aug_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regional Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional CV models\n",
    "REGIONAL_MODELS = {\n",
    "    \"North\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/regional-cv/segformer_cv_north.yaml\",\n",
    "        \"ckpt\": \"/mnt/class_data/sdalgarno/checkpoints/regional-cv/north/last-v1.ckpt\",\n",
    "    },\n",
    "    \"Central\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/regional-cv/segformer_cv_central.yaml\",\n",
    "        \"ckpt\": \"/mnt/class_data/sdalgarno/checkpoints/regional-cv/central/last-v1.ckpt\",\n",
    "    },\n",
    "    \"South\": {\n",
    "        \"config\": \"../configs/seagrass-rgb/regional-cv/segformer_cv_south.yaml\",\n",
    "        \"ckpt\": \"/mnt/class_data/sdalgarno/checkpoints/regional-cv/south/last-v1.ckpt\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Evaluate on test only\n",
    "regional_results = []\n",
    "for region, paths in REGIONAL_MODELS.items():\n",
    "    print(f\"Evaluating {region}...\")\n",
    "    test_metrics = evaluate_model(paths[\"config\"], paths[\"ckpt\"], split=\"test\")\n",
    "    regional_results.append({\n",
    "        \"Model\": region, \n",
    "        \"IoU\": test_metrics[\"IoU\"],\n",
    "        \"Precision\": test_metrics[\"Precision\"],\n",
    "        \"Recall\": test_metrics[\"Recall\"],\n",
    "    })\n",
    "    print(f\"  Test IoU: {test_metrics['IoU']:.4f}\")\n",
    "\n",
    "regional_df = pd.DataFrame(regional_results).set_index(\"Model\")\n",
    "regional_df.to_csv(OUTPUT_DIR / \"regional_cv.csv\")\n",
    "regional_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model config and checkpoint\n",
    "FINAL_MODEL = {\n",
    "    \"config\": \"../configs/seagrass-rgb/segformer_train50.yaml\",\n",
    "    \"ckpt\": \"/mnt/class_data/sdalgarno/checkpoints/segformer-train50/segformer_train50_epoch-299_val-iou-0.8837.ckpt\",\n",
    "}\n",
    "\n",
    "# Evaluate on val and test\n",
    "print(\"Evaluating Final Model...\")\n",
    "final_val = evaluate_model(FINAL_MODEL[\"config\"], FINAL_MODEL[\"ckpt\"], split=\"val\")\n",
    "final_test = evaluate_model(FINAL_MODEL[\"config\"], FINAL_MODEL[\"ckpt\"], split=\"test\")\n",
    "\n",
    "# Create results table\n",
    "final_results = pd.DataFrame({\n",
    "    \"Val\": final_val,\n",
    "    \"Test\": final_test,\n",
    "}).T\n",
    "\n",
    "final_results.to_csv(OUTPUT_DIR / \"final_model.csv\")\n",
    "print(\"\\nFinal Model Metrics:\")\n",
    "final_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hakai-ml-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
